{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f668fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509bf3c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Livia - Team Brainwave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fecb45",
   "metadata": {
    "cell_marker": "#############################################"
   },
   "source": [
    "1. IMPORT LIBRARIES & MOUNT DRIVE\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from scipy.stats import zscore, pearsonr, uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c19c0b",
   "metadata": {
    "cell_marker": "#############################################"
   },
   "source": [
    "2. LOAD DATAFRAMES\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Functions\n",
    "def load_csv(file_path, name=\"\"):\n",
    "    \"\"\"Load CSV file with error handling.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"{name} shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define file paths for local machine\n",
    "base_path = r\"C:\\Users\\livia\\OneDrive\\Documents\\data_test\"  # Use raw string to handle backslashes\n",
    "data_files = {\n",
    "    'train_cat': 'TRAIN_CATEGORICAL.csv',\n",
    "    'train_fcm': 'TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv',\n",
    "    'train_quant': 'TRAIN_QUANTITATIVE.csv',\n",
    "    'train_solutions': 'TRAINING_SOLUTIONS.csv',\n",
    "    'test_cat': 'TEST_CATEGORICAL.csv',\n",
    "    'test_quant': 'TEST_QUANTITATIVE.csv',\n",
    "    'test_fcm': 'TEST_FCM.csv'\n",
    "}\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "for name, filename in data_files.items():\n",
    "    file_path = os.path.join(base_path, filename)  # Correctly join path and filename\n",
    "    datasets[name] = load_csv(file_path, name)\n",
    "\n",
    "# Check if all datasets loaded successfully\n",
    "if any(df is None for df in datasets.values()):\n",
    "    raise Exception(\"One or more datasets failed to load\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee337f",
   "metadata": {
    "cell_marker": "#############################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "3. MERGE NON-FCM TRAINING & TEST DATA\n",
    "############################################\n",
    "Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c4e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(cat_df, quant_df, name=\"\"):\n",
    "    \"\"\"Merge categorical and quantitative datasets.\"\"\"\n",
    "    merged_df = pd.merge(cat_df, quant_df, on='participant_id', how='inner')\n",
    "\n",
    "    print(f\"{name} merged shape: {merged_df.shape}\")\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# Prepare training and test data\n",
    "train_df = merge_datasets(datasets['train_cat'], datasets['train_quant'], \"Training\")\n",
    "test_df = merge_datasets(datasets['test_cat'], datasets['test_quant'], \"Test\")\n",
    "\n",
    "\n",
    "# Prepare features and targets\n",
    "X_train = train_df.drop(columns=['participant_id'])\n",
    "Y_train = datasets['train_solutions'][['ADHD_Outcome', 'Sex_F']]\n",
    "participant_ids = test_df['participant_id']\n",
    "X_test = test_df.drop(columns=['participant_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbd6bc",
   "metadata": {
    "cell_marker": "#############################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "4. PROCESS FCM DATA WITH A GNN TO GET EMBEDDINGS\n",
    "############################################\n",
    "We'll process the FCM data to generate graph embeddings from a GCN.\n",
    "Both training and test FCM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbe463",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FCM = datasets['train_fcm']\n",
    "test_FCM  = datasets['test_fcm']\n",
    "\n",
    "# Drop participant_id for processing but save it for merging later.\n",
    "train_FCM_proc = train_FCM.drop(columns=['participant_id'])\n",
    "test_FCM_proc  = test_FCM.drop(columns=['participant_id'])\n",
    "\n",
    "# --- Convert each vector into an adjacency matrix ---\n",
    "def vector_to_adjacency(vector):\n",
    "    # Assumes a 200x200 symmetric matrix (excluding diagonal)\n",
    "    adj_matrix = np.zeros((200, 200))\n",
    "    triu_indices = np.triu_indices(200, k=1)\n",
    "    adj_matrix[triu_indices] = vector\n",
    "    adj_matrix += adj_matrix.T\n",
    "    return adj_matrix\n",
    "\n",
    "# Compute adjacency matrices (each row in train_FCM_proc is converted)\n",
    "adj_matrices_train = np.array([vector_to_adjacency(row) for row in train_FCM_proc.to_numpy()])\n",
    "adj_matrices_test  = np.array([vector_to_adjacency(row) for row in test_FCM_proc.to_numpy()])\n",
    "\n",
    "# --- Convert adjacency matrix to edge list for PyG ---\n",
    "def adjacency_to_edge_list(adj_matrix, threshold=0.1):\n",
    "    edge_index = np.array(np.where(adj_matrix > threshold))\n",
    "    edge_weight = adj_matrix[edge_index[0], edge_index[1]]\n",
    "    return torch.tensor(edge_index, dtype=torch.long), torch.tensor(edge_weight, dtype=torch.float)\n",
    "\n",
    "edge_data_train = [adjacency_to_edge_list(adj) for adj in adj_matrices_train]\n",
    "edge_indices_train = [data[0] for data in edge_data_train]\n",
    "edge_weights_train = [data[1] for data in edge_data_train]\n",
    "\n",
    "edge_data_test = [adjacency_to_edge_list(adj) for adj in adj_matrices_test]\n",
    "edge_indices_test = [data[0] for data in edge_data_test]\n",
    "edge_weights_test = [data[1] for data in edge_data_test]\n",
    "\n",
    "# --- Create PyG graph objects ---\n",
    "# Use an identity matrix for node features (each graph has 200 nodes)\n",
    "graphs_train = [Data(x=torch.eye(200), edge_index=e_idx, edge_attr=e_wt)\n",
    "                for e_idx, e_wt in zip(edge_indices_train, edge_weights_train)]\n",
    "graphs_test  = [Data(x=torch.eye(200), edge_index=e_idx, edge_attr=e_wt)\n",
    "                for e_idx, e_wt in zip(edge_indices_test, edge_weights_test)]\n",
    "\n",
    "# --- Define a simple GCN to extract graph embeddings ---\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # Global pooling to get graph-level embedding\n",
    "        x = global_mean_pool(x, batch)  # shape: [num_graphs, hidden_channels]\n",
    "        return x\n",
    "\n",
    "# Instantiate the model; here we use 200 input channels and output a 64-dim embedding\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_gcn = GCN(in_channels=200, hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model_gcn.parameters(), lr=0.001)\n",
    "\n",
    "# --- Train the GCN (for demonstration, we train for a few epochs with a dummy loss) ---\n",
    "model_gcn.train()\n",
    "batch_train = Batch.from_data_list(graphs_train).to(device)\n",
    "for epoch in range(20):  # Adjust epochs as needed\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model_gcn(batch_train)  # shape: [num_train, 64]\n",
    "    loss = embeddings.norm()  # dummy loss; in practice, use a proper unsupervised loss or pre-trained model\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"GCN Epoch {epoch}, loss: {loss.item():.4f}\")\n",
    "model_gcn.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_train = model_gcn(batch_train)  # tensor shape: [num_train, 64]\n",
    "    batch_test = Batch.from_data_list(graphs_test).to(device)\n",
    "    embeddings_test = model_gcn(batch_test)    # tensor shape: [num_test, 64]\n",
    "\n",
    "# Convert embeddings to numpy arrays\n",
    "embeddings_train_np = embeddings_train.cpu().numpy()\n",
    "embeddings_test_np = embeddings_test.cpu().numpy()\n",
    "\n",
    "# Create DataFrames for embeddings with participant_id\n",
    "df_embeddings_train = pd.DataFrame(embeddings_train_np, columns=[f'GNN_feat_{i}' for i in range(64)])\n",
    "df_embeddings_train['participant_id'] = train_FCM['participant_id'].values\n",
    "\n",
    "df_embeddings_test = pd.DataFrame(embeddings_test_np, columns=[f'GNN_feat_{i}' for i in range(64)])\n",
    "df_embeddings_test['participant_id'] = test_FCM['participant_id'].values\n",
    "\n",
    "# --- Merge GNN embeddings with your previously merged data ---\n",
    "train_df_with_gnn = pd.merge(train_df, df_embeddings_train, on='participant_id', how='left')\n",
    "test_df_with_gnn  = pd.merge(test_df, df_embeddings_test, on='participant_id', how='left')\n",
    "\n",
    "# Update X_train and X_test to include GNN features\n",
    "X_train = train_df_with_gnn.drop(columns=['participant_id'])\n",
    "X_test  = test_df_with_gnn.drop(columns=['participant_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe1eff",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f64535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# Machine Learning Pipeline\n",
    "def create_preprocessor(X):\n",
    "    \"\"\"Create preprocessing pipeline for numeric and categorical features.\"\"\"\n",
    "    numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define custom scoring function\n",
    "def multi_output_accuracy(y_true, y_pred):\n",
    "    \"\"\"Calculate average accuracy across multiple outputs.\"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.mean([accuracy_score(y_true[:, i], y_pred[:, i])\n",
    "                   for i in range(y_true.shape[1])])\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train_split, X_val, Y_train_split, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train\n",
    ")\n",
    "\n",
    "# Create and train model\n",
    "preprocessor = create_preprocessor(X_train)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MultiOutputClassifier(XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_dist = {\n",
    "    'classifier__estimator__n_estimators': [50, 100, 200],\n",
    "    'classifier__estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__estimator__max_depth': [3, 5, 7],\n",
    "    'classifier__estimator__subsample': [0.8, 0.9, 1.0],\n",
    "    'classifier__estimator__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring=make_scorer(multi_output_accuracy),\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Fit model and get results\n",
    "search.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best cross-validation score:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173319b6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef97310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "Y_val_pred = search.predict(X_val)\n",
    "Y_val_pred_proba = search.predict_proba(X_val)  # Probability predictions for ROC-AUC\n",
    "\n",
    "# Extract predictions and true values for each target\n",
    "Y_val_adhd, Y_val_sex = Y_val['ADHD_Outcome'], Y_val['Sex_F']\n",
    "Y_pred_adhd, Y_pred_sex = Y_val_pred[:, 0], Y_val_pred[:, 1]\n",
    "Y_pred_proba_adhd = [x[1] for x in Y_val_pred_proba[0]]  # Probability of positive class for ADHD\n",
    "Y_pred_proba_sex = [x[1] for x in Y_val_pred_proba[1]]   # Probability of positive class for Sex_F\n",
    "\n",
    "def print_metrics(y_true, y_pred, y_pred_proba, target_name):\n",
    "    print(f\"\\n--- Metrics for {target_name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"F1-Score: {f1_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_true, y_pred_proba):.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Print metrics for each target\n",
    "print_metrics(Y_val_adhd, Y_pred_adhd, Y_pred_proba_adhd, \"ADHD_Outcome\")\n",
    "print_metrics(Y_val_sex, Y_pred_sex, Y_pred_proba_sex, \"Sex_F\")\n",
    "\n",
    "# # Function to plot confusion matrix\n",
    "# def plot_confusion_matrix(y_true, y_pred, target_name):\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "#     plt.title(f'Confusion Matrix for {target_name}')\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('True')\n",
    "#     plt.show()\n",
    "\n",
    "# # Plot confusion matrices\n",
    "# plot_confusion_matrix(Y_val_adhd, Y_pred_adhd, \"ADHD_Outcome\")\n",
    "# plot_confusion_matrix(Y_val_sex, Y_pred_sex, \"Sex_F\")\n",
    "\n",
    "# # Function to plot ROC curve\n",
    "# def plot_roc_curve(y_true, y_pred_proba, target_name):\n",
    "#     fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y_true, y_pred_proba):.3f})')\n",
    "#     plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title(f'ROC Curve for {target_name}')\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.show()\n",
    "\n",
    "# # Plot ROC curves\n",
    "# plot_roc_curve(Y_val_adhd, Y_pred_proba_adhd, \"ADHD_Outcome\")\n",
    "# plot_roc_curve(Y_val_sex, Y_pred_proba_sex, \"Sex_F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51b57f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Prediction submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = search.predict(X_test)\n",
    "predictions_df = pd.DataFrame(\n",
    "    y_pred,\n",
    "    columns=['Predicted_ADHD', 'Predicted_Sex'],\n",
    "    index=participant_ids\n",
    ").reset_index()\n",
    "\n",
    "# Save results\n",
    "output_path = 'submission.csv'\n",
    "predictions_df.to_csv(output_path, index=False)\n",
    "print(f\"Predictions saved to {output_path}\")\n",
    "print(predictions_df.head())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
